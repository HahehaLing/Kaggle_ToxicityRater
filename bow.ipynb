{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUPQ03ozgN6"
   },
   "source": [
    "# Comment Toxicity Severity Rater\n",
    "- group by the same comment and find out if that comment is more often rated as more/ less toxic \n",
    "- transform the input data to be more / less toxic 0 and 1 // train on these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies \n",
    "check the requirements.txt file\n",
    "\n",
    "\n",
    "### can't install tensorflow on m1 // not going to use keras lstm locally (can check on gColab)\n",
    "tensorflow: use pip install tensorflow OR if mac m1: python3 -m pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "JK2ClqlvzPs7"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YBi80m2m0wO4"
   },
   "outputs": [],
   "source": [
    "# remove special characters using the regular expression library\n",
    "# updated with . and = \n",
    "import re\n",
    "\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\*)|(\\=\\=)|(\\~) | (\\=) | (\\.\\.\\.) |(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\" (<br\\s/><br\\s/?)| (\\n\\n) | (\\n) |(\\.) |(-)|(/)|(:). \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "NsFs8bzc0ylC"
   },
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "jdxdQ2Fz00L3"
   },
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"./data/validation_data.csv\")\n",
    "\n",
    "data_to_test = pd.read_csv('./data/comments_to_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "original_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!!!!!!!!??????????????????????????????????????????????????????!!!!!!=\\nWHER IS YOUR SEXY PIC GONE FROM YOUR MAIN PAGE???????? put it back'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original_data.iloc[0]\n",
    "original_data['more_toxic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = original_data\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_less_toxic = clean_tweets(original_data[\"less_toxic\"])\n",
    "cleaned_data['less_toxic'] = pd.DataFrame(clean_less_toxic)\n",
    "#cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>this article sucks woo woo wooooooo</td>\n",
       "      <td>what=wher is your sexy pic gone from your main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>and yes people should recognize that but they ...</td>\n",
       "      <td>daphne guinness top of the mornin my favourite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>western mediayup because every crime in the en...</td>\n",
       "      <td>atom you dont believe actual photos of masturb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>and you removed it you numbskull i dont care w...</td>\n",
       "      <td>you seem to have sand in your vagina.might wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina bluerasberry why dont you be a m...</td>\n",
       "      <td>hey way to support nazis you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>im sorry im not an admin i will give you three...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>im sorry im not an admin i will give you three...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...are you out of your mind how was my edit...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...are you out of your mind how was my edit...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...are you out of your mind how was my edit...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313                this article sucks woo woo wooooooo   \n",
       "1         188  and yes people should recognize that but they ...   \n",
       "2          82  western mediayup because every crime in the en...   \n",
       "3         347  and you removed it you numbskull i dont care w...   \n",
       "4         539  smelly vagina bluerasberry why dont you be a m...   \n",
       "...       ...                                                ...   \n",
       "30103     461  im sorry im not an admin i will give you three...   \n",
       "30104     527  im sorry im not an admin i will give you three...   \n",
       "30105     352  wow...are you out of your mind how was my edit...   \n",
       "30106     311  wow...are you out of your mind how was my edit...   \n",
       "30107      54  wow...are you out of your mind how was my edit...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      what=wher is your sexy pic gone from your main...  \n",
       "1      daphne guinness top of the mornin my favourite...  \n",
       "2      atom you dont believe actual photos of masturb...  \n",
       "3      you seem to have sand in your vagina.might wan...  \n",
       "4                    hey way to support nazis you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       piss off you slant eyed gook  \n",
       "30106                       piss off you slant eyed gook  \n",
       "30107                       piss off you slant eyed gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_more_toxic = clean_tweets(original_data[\"more_toxic\"])\n",
    "cleaned_data['more_toxic'] = pd.DataFrame(clean_more_toxic)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cody porter dies while foolishly copying kimimaro kaguya    okay we need to add this seriously i mean we added the crap about a freakin death note so i believe we definitely should add this especially since a little ten year old baka died     news report t  c     this has already been discussed before here check that discussion for the news reports and why we decided not to include it also he was imitating gaara not kimmimaro warranting the nickname of s& sand hero from  b  got a present for ya  mission log   heres where it went wrong  no he was copying kimimaro dont believe every little detail from a reporter who calls it nerutu sand ninjas.. gaara was using armor he wasnt actually buried sorry if i sound aggressive but i know my naruto   i seriosly dont want to be rude but these parents and a whole ton of other people are clueless they all think that naruto is some weird kids show like doraemon or pokmon no it was made for teenagers well in the of age or older and was serialized in a teenager magazine its stupid these companys make all of em look like pokmon so they all think they are for little children now look at what you got a clueless news reporter calling it neruto sand ninjas and a bunch of perverted little children saying haha sexy justu haha it really gets on my nerves  the free encyclopedia   nah it was gaara teh internets have decided that he was imitating gaara dubbing him the sand hero and i have no reason to doubt the accuracy of the internets got a present for ya  mission log     if he were copying kimimaro hed be trying to remove his femur for use in a rousing game of hoop and stick now that would be worth watching ~to     i dont know whether to find that hilarious or disturbing perhaps both t  c  oh by the way leafninja isnt a fansite.\n",
      "11503\n",
      "11644\n"
     ]
    }
   ],
   "source": [
    "grouped_df_less = original_data.groupby(['less_toxic']).size()\n",
    "\n",
    "print(grouped_df_less.index[0])\n",
    "#grouped_df_less.values[0]\n",
    "\n",
    "grouped_df_more = original_data.groupby(['more_toxic']).size()\n",
    "#grouped_df_more.index[0]\n",
    "\n",
    "print(len(grouped_df_less.values))\n",
    "print(len(grouped_df_more.values))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check: is the following 2 cells a mega inefficient way lol\n",
    "\n",
    "transforming for a new column by checking if the comment is rated a more / less toxic in general\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_less = len(grouped_df_less.index)\n",
    "n_more = len(grouped_df_more.index)\n",
    "\n",
    "comment = []\n",
    "score = []\n",
    "\n",
    "for i in range(n_more):\n",
    "    if grouped_df_more.index[i] not in grouped_df_less.index:\n",
    "            comment.append(grouped_df_more.index[i])\n",
    "            score.append(1)\n",
    "            continue\n",
    "    for j in range(n_less): \n",
    "        #if grouped_df_less.index[j] not in grouped_df_more.index:\n",
    "         #   comment.append(grouped_df_less.index[j])\n",
    "          #  score.append(0)\n",
    "           # continue \n",
    "        \n",
    "        if grouped_df_less.index[j] == grouped_df_more.index[i]:\n",
    "            comment.append(grouped_df_less.index[j])\n",
    "            if grouped_df_more.values[i] >= grouped_df_less.values[j]:\n",
    "                score.append(1)\n",
    "            else:\n",
    "                score.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11644\n",
      "11644\n"
     ]
    }
   ],
   "source": [
    "print(len(comment))\n",
    "print(len(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=            =                    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cody porter dies while foolishly copying ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i get it the page is about all the doomsday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invention   what on earth are you talking a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is she black   why dose it matter what race...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11639</th>\n",
       "      <td>zora you seem to assume that i have not done m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11640</th>\n",
       "      <td>zulfiqar ali bhutto stop vandalizing zulfiqar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>zzzzzzz.. youre a real bore now go bore someon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>~whats with you that youre so annoying and pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11643</th>\n",
       "      <td>~~its okay of course for them to have their ow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11644 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  score\n",
       "0                  =            =                    ...      1\n",
       "1         cody porter dies while foolishly copying ki...      0\n",
       "2         i get it the page is about all the doomsday...      0\n",
       "3         invention   what on earth are you talking a...      0\n",
       "4         is she black   why dose it matter what race...      1\n",
       "...                                                  ...    ...\n",
       "11639  zora you seem to assume that i have not done m...      1\n",
       "11640  zulfiqar ali bhutto stop vandalizing zulfiqar ...      1\n",
       "11641  zzzzzzz.. youre a real bore now go bore someon...      0\n",
       "11642  ~whats with you that youre so annoying and pro...      1\n",
       "11643  ~~its okay of course for them to have their ow...      1\n",
       "\n",
       "[11644 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = pd.DataFrame(comment, columns = ['comment'])\n",
    "trans['score'] = pd.DataFrame(score, columns = ['score'])\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these comments are all categorized as less toxic \n",
    "for j in range(n_less): \n",
    "        if grouped_df_less.index[j] not in grouped_df_more.index:\n",
    "            comment.append(grouped_df_less.index[j])\n",
    "            score.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14208\n",
      "14208\n"
     ]
    }
   ],
   "source": [
    "print(len(comment))\n",
    "print(len(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=            =                    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cody porter dies while foolishly copying ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i get it the page is about all the doomsday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invention   what on earth are you talking a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is she black   why dose it matter what race...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>yuber youre the pov pusher and stalking my con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14204</th>\n",
       "      <td>yuberplease do something about yubers constant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14205</th>\n",
       "      <td>ywhy arnt i allowed to contribute when i just ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14206</th>\n",
       "      <td>zionist jewplease stop spreadin your lies bias...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>~i heard that dick gephardt was actually presi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  score\n",
       "0                  =            =                    ...      1\n",
       "1         cody porter dies while foolishly copying ki...      0\n",
       "2         i get it the page is about all the doomsday...      0\n",
       "3         invention   what on earth are you talking a...      0\n",
       "4         is she black   why dose it matter what race...      1\n",
       "...                                                  ...    ...\n",
       "14203  yuber youre the pov pusher and stalking my con...      0\n",
       "14204  yuberplease do something about yubers constant...      0\n",
       "14205  ywhy arnt i allowed to contribute when i just ...      0\n",
       "14206  zionist jewplease stop spreadin your lies bias...      0\n",
       "14207  ~i heard that dick gephardt was actually presi...      0\n",
       "\n",
       "[14208 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = pd.DataFrame(comment, columns = ['comment'])\n",
    "trans['score'] = pd.DataFrame(score, columns = ['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "count  14208.0\n",
       "mean       1.0\n",
       "std        0.0\n",
       "min        1.0\n",
       "25%        1.0\n",
       "50%        1.0\n",
       "75%        1.0\n",
       "max        1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing to see if the transformation data only appears once now (expected). Want every comment\n",
    "# to be either more or less toxic\n",
    "pd.DataFrame(trans.groupby(['comment']).size().values).describe() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "0    6765\n",
       "1    7443\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.groupby(['score']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=            =                    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cody porter dies while foolishly copying ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i get it the page is about all the doomsday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invention   what on earth are you talking a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is she black   why dose it matter what race...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>yuber youre the pov pusher and stalking my con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14204</th>\n",
       "      <td>yuberplease do something about yubers constant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14205</th>\n",
       "      <td>ywhy arnt i allowed to contribute when i just ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14206</th>\n",
       "      <td>zionist jewplease stop spreadin your lies bias...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>~i heard that dick gephardt was actually presi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  score\n",
       "0                  =            =                    ...      1\n",
       "1         cody porter dies while foolishly copying ki...      0\n",
       "2         i get it the page is about all the doomsday...      0\n",
       "3         invention   what on earth are you talking a...      0\n",
       "4         is she black   why dose it matter what race...      1\n",
       "...                                                  ...    ...\n",
       "14203  yuber youre the pov pusher and stalking my con...      0\n",
       "14204  yuberplease do something about yubers constant...      0\n",
       "14205  ywhy arnt i allowed to contribute when i just ...      0\n",
       "14206  zionist jewplease stop spreadin your lies bias...      0\n",
       "14207  ~i heard that dick gephardt was actually presi...      0\n",
       "\n",
       "[14208 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "c83rXllE12qD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract the labels from the train data\n",
    "y = trans.score.values\n",
    "X = trans.comment.values\n",
    "\n",
    "# use 60% for the training, 20% validation, and 20% for the test\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1, \n",
    "                                                    test_size=0.2, shuffle=True)\n",
    "# train\n",
    "x_train = x_train_all[int(x_train_all.shape[0]/4):]\n",
    "y_train = x_train_all[int(y_train_all.shape[0]/4):]\n",
    "\n",
    "#valid\n",
    "x_val = x_train_all[:int(x_train_all.shape[0]/4)]\n",
    "y_val = x_train_all[:int(y_train_all.shape[0]/4)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>gjalexei you asked about whether there is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>looks like be have an abuser  can you please l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>i confess to having complete and apparently bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>freuds ideas are certainly much discussed toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>it is not just you this is a laundry list of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>504235362</td>\n",
       "      <td>go away you annoying vandal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>504235566</td>\n",
       "      <td>this user is a vandal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>504308177</td>\n",
       "      <td>sorry to sound like a pain but one by followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>504570375</td>\n",
       "      <td>well its pretty fucking irrelevant now im unbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>504598250</td>\n",
       "      <td>the team name is great britain and northern ir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                               text\n",
       "0         114890   gjalexei you asked about whether there is an ...\n",
       "1         732895  looks like be have an abuser  can you please l...\n",
       "2        1139051  i confess to having complete and apparently bl...\n",
       "3        1434512  freuds ideas are certainly much discussed toda...\n",
       "4        2084821  it is not just you this is a laundry list of s...\n",
       "...          ...                                                ...\n",
       "7532   504235362                       go away you annoying vandal.\n",
       "7533   504235566                             this user is a vandal.\n",
       "7534   504308177   sorry to sound like a pain but one by followi...\n",
       "7535   504570375  well its pretty fucking irrelevant now im unbl...\n",
       "7536   504598250  the team name is great britain and northern ir...\n",
       "\n",
       "[7537 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean the input for predition data\n",
    "cleaned_text = clean_tweets(data_to_test['text'])\n",
    "\n",
    "data_to_test['text'] = pd.DataFrame(cleaned_text)\n",
    "data_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "uVP8iy3t6qtG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initalize vectorizer: vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english') #stop_words removed: a, the\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train_all) + list(x_test) + list(data_to_test[\"text\"].values))\n",
    "    \n",
    "\n",
    "# transform documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_train_val_vec = vectorizer.transform(x_train_all)\n",
    "x_valve_vec = vectorizer.transform(x_val)\n",
    "\n",
    "\n",
    "x_test_vec = vectorizer.transform(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest:  0.609096631238619\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "cv_scores = cross_val_score(clf, x_train_val_vec, y_train_all, cv=10)\n",
    "\n",
    "print ('random forest: ',cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5512023548502979\n",
      "2 0.5609703073321194\n",
      "3 0.5720559725990065\n",
      "4 0.5686223320574281\n",
      "5 0.5624646958266751\n",
      "6 0.571175613487433\n",
      "7 0.5613207167366556\n",
      "8 0.5728458260557187\n",
      "9 0.5587683643638435\n",
      "10 0.5665985358058643\n",
      "11 0.5599116466609685\n",
      "12 0.5651014375611629\n",
      "13 0.5590337650352423\n",
      "14 0.5629917809407013\n"
     ]
    }
   ],
   "source": [
    "#KNN choosing best neighbour number \n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "for n in range(1, 15):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    cv_scores = cross_val_score(clf, x_train_val_vec, y_train_all, cv=10)\n",
    "    print (n, cv_scores.mean())\n",
    "    \n",
    "#k = 8 , 3 are first and sec place for best predictor respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5728458260557187"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN \n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=8)\n",
    "cv_scores = cross_val_score(clf, x_train_val_vec, y_train_all, cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6199204572200131"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "cv_scores = cross_val_score(clf, x_train_val_vec, y_train_all, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax scaled Baye's:  0.6206232889863367\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "#usually not the best performance, but fast to train\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "scaler = preprocessing.MaxAbsScaler() #don't really need scaling since the input is already binary \n",
    "training_inputs_minmax = scaler.fit_transform(x_train_val_vec)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores = cross_val_score(clf, training_inputs_minmax, y_train_all, cv=10)\n",
    "\n",
    "print ('minmax scaled Baye\\'s: ',cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel 0.6077753570676478\n",
      "rbf kernel 0.6370746466485809\n",
      "sigmoid kernel 0.612352279906351\n",
      "poly kernel 0.5293857693212928\n"
     ]
    }
   ],
   "source": [
    "#SVM with kernel tuning\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "C = 1.0\n",
    "svc = svm.SVC(kernel='linear', C=C)\n",
    "cv_scores = cross_val_score(svc, x_train_val_vec, y_train_all, cv=10)\n",
    "print ('linear kernel', cv_scores.mean())\n",
    "\n",
    "\n",
    "svc = svm.SVC(kernel='rbf', C=C)\n",
    "cv_scores = cross_val_score(svc, x_train_val_vec, y_train_all, cv=10)\n",
    "cv_scores.mean()\n",
    "print ('rbf kernel', cv_scores.mean())\n",
    "\n",
    "\n",
    "svc = svm.SVC(kernel='sigmoid', C=C)\n",
    "cv_scores = cross_val_score(svc, x_train_val_vec, y_train_all, cv=10)\n",
    "cv_scores.mean()\n",
    "print ('sigmoid kernel', cv_scores.mean())\n",
    "\n",
    "svc = svm.SVC(kernel='poly', C=C)\n",
    "cv_scores = cross_val_score(svc, x_train_val_vec, y_train_all, cv=10)\n",
    "cv_scores.mean()\n",
    "print ('poly kernel', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='sigmoid', C=C)\n",
    "cv_scores = cross_val_score(svc, x_train_val_vec, y_train_all, cv=10)\n",
    "cv_scores.mean()\n",
    "print ('sigmoid kernel', cv_scores.mean()) #63.7% accuracy // highest of the above models so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try on colab: keras lstm, xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEsTR7Cm618L"
   },
   "outputs": [],
   "source": [
    "prof_less = prof_check([test[\"less_toxic_clean_tweet\"]]) \n",
    "prof_less = np.array(prof_less[0]) #predicted less toxic tweet's profanity prob\n",
    "\n",
    "prof_more = prof_check([test[\"more_toxic_clean_tweet\"]]) \n",
    "prof_more = np.array(prof_more[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLYXpYyn7eu_"
   },
   "outputs": [],
   "source": [
    "exc_less = exc_cnt(test[\"less_toxic_clean_tweet\"]) #exclamation mark counter if the profanity score is more than 0.5\n",
    "exc_more = exc_cnt(test[\"more_toxic_clean_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rh6Z09d7osC"
   },
   "outputs": [],
   "source": [
    "tox_prob_less = calibrated_clf.predict_proba(x_val_less)\n",
    "tox_prob_more = calibrated_clf.predict_proba(x_val_more)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWVF6ygD8NRn"
   },
   "outputs": [],
   "source": [
    "pred_less = tox_prob_less[:,1] + exc_less + prof_less \n",
    "pred_more = tox_prob_more[:,1] + exc_more + prof_more"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "offtheshelf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kaggle_kernel",
   "language": "python",
   "name": "kaggle_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
