{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUPQ03ozgN6"
   },
   "source": [
    "# Comment Toxicity Severity Rater\n",
    "- group by the same comment and find out if that comment is more often rated as more/ less toxic \n",
    "- transform the input data to be more / less toxic 0 and 1 // train on these\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IR61GQ1Qywzb",
    "outputId": "67ef639b-e210-4526-ff0f-b484165995f4"
   },
   "outputs": [],
   "source": [
    "#!pip install alt-profanity-check\n",
    "!pip install joblib\n",
    "!pip install scikit-learn\n",
    "#install tweet-preprocessor to clean tweets\n",
    "!pip install tweet-preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JK2ClqlvzPs7"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YBi80m2m0wO4"
   },
   "outputs": [],
   "source": [
    "# remove special characters using the regular expression library\n",
    "# updated with . and = \n",
    "import re\n",
    "\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\*)|(\\=\\=)|(\\~) | (\\=) | (\\.\\.\\.) |(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\" (<br\\s/><br\\s/?)| (\\n\\n) | (\\n) |(\\.) |(-)|(/)|(:). \")\n",
    "\n",
    "#re.escape (* )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re.sub() // natalie uses this more often\n",
    "\n",
    "# regex has a method to escape the char properly \n",
    "re.escape\n",
    "\n",
    "\n",
    "# gridsearchcv() // can be slow \n",
    "if have a few val, can use \n",
    "\n",
    "# use randomsearch() // possible range // faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NsFs8bzc0ylC"
   },
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jdxdQ2Fz00L3"
   },
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"./data/validation_data.csv\")\n",
    "\n",
    "data_to_test = pd.read_csv('./data/comments_to_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Jcgva1U5yJYN",
    "outputId": "478c0002-a327-4233-a62c-c62d16907adf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "original_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "5beXEglKyJYO",
    "outputId": "212d55c9-b984-47ed-dd95-8538a49ce5d9"
   },
   "outputs": [],
   "source": [
    "#original_data.iloc[0]\n",
    "#original_data['more_toxic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4Ned_u-3yJYO",
    "outputId": "d01310d0-1d89-4cb0-d6f4-41fb292e9213"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = original_data\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3ynSbwXpyJYP"
   },
   "outputs": [],
   "source": [
    "clean_less_toxic = clean_tweets(original_data[\"less_toxic\"])\n",
    "cleaned_data['less_toxic'] = pd.DataFrame(clean_less_toxic)\n",
    "#cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "JUnN_J62yJYP",
    "outputId": "cc219ae9-801f-4413-e66b-179801803916"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>this article sucks woo woo wooooooo</td>\n",
       "      <td>what=wher is your sexy pic gone from your main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>and yes people should recognize that but they ...</td>\n",
       "      <td>daphne guinness top of the mornin my favourite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>western mediayup because every crime in the en...</td>\n",
       "      <td>atom you dont believe actual photos of masturb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>and you removed it you numbskull i dont care w...</td>\n",
       "      <td>you seem to have sand in your vagina.might wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina bluerasberry why dont you be a m...</td>\n",
       "      <td>hey way to support nazis you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>im sorry im not an admin i will give you three...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>im sorry im not an admin i will give you three...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...are you out of your mind how was my edit...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...are you out of your mind how was my edit...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...are you out of your mind how was my edit...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313                this article sucks woo woo wooooooo   \n",
       "1         188  and yes people should recognize that but they ...   \n",
       "2          82  western mediayup because every crime in the en...   \n",
       "3         347  and you removed it you numbskull i dont care w...   \n",
       "4         539  smelly vagina bluerasberry why dont you be a m...   \n",
       "...       ...                                                ...   \n",
       "30103     461  im sorry im not an admin i will give you three...   \n",
       "30104     527  im sorry im not an admin i will give you three...   \n",
       "30105     352  wow...are you out of your mind how was my edit...   \n",
       "30106     311  wow...are you out of your mind how was my edit...   \n",
       "30107      54  wow...are you out of your mind how was my edit...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      what=wher is your sexy pic gone from your main...  \n",
       "1      daphne guinness top of the mornin my favourite...  \n",
       "2      atom you dont believe actual photos of masturb...  \n",
       "3      you seem to have sand in your vagina.might wan...  \n",
       "4                    hey way to support nazis you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       piss off you slant eyed gook  \n",
       "30106                       piss off you slant eyed gook  \n",
       "30107                       piss off you slant eyed gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_more_toxic = clean_tweets(original_data[\"more_toxic\"])\n",
    "cleaned_data['more_toxic'] = pd.DataFrame(clean_more_toxic)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>9</td>\n",
       "      <td>its not so much about the english language its...</td>\n",
       "      <td>i hate drmies he is an idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17914</th>\n",
       "      <td>431</td>\n",
       "      <td>just read what mr george mcfly said here that ...</td>\n",
       "      <td>i fuckingg love tacosthere the fuckingg best b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>338</td>\n",
       "      <td>a barnstar for you the original barnstar your...</td>\n",
       "      <td>fuck you fuck you motherfucker go die in a hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24121</th>\n",
       "      <td>386</td>\n",
       "      <td>i am one who thinks that zappas dad was of ara...</td>\n",
       "      <td>jimbo wales is a gay little fucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22424</th>\n",
       "      <td>397</td>\n",
       "      <td>a cup of coffee for you get fuckd with coffee</td>\n",
       "      <td>dude im not angry at you i just think youre a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>422</td>\n",
       "      <td>please stop your disruptive editing if you co...</td>\n",
       "      <td>youre a mathsci sockpuppet arent you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>293</td>\n",
       "      <td>dude you both are dumb in the heavier than hea...</td>\n",
       "      <td>mahmoud ahmadinejadi added the categoryanti se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>347</td>\n",
       "      <td>then i guess i eat poop</td>\n",
       "      <td>racisttrying to whitewash the terrorists fine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>728</td>\n",
       "      <td>i thought you were the administrator can you f...</td>\n",
       "      <td>just because she has light skin doesnt mean an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>132</td>\n",
       "      <td>not set in new york  why when i deleted the ca...</td>\n",
       "      <td>what the hell is that thing on the electoral m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "14331       9  its not so much about the english language its...   \n",
       "17914     431  just read what mr george mcfly said here that ...   \n",
       "14390     338   a barnstar for you the original barnstar your...   \n",
       "24121     386  i am one who thinks that zappas dad was of ara...   \n",
       "22424     397     a cup of coffee for you get fuckd with coffee    \n",
       "...       ...                                                ...   \n",
       "13123     422   please stop your disruptive editing if you co...   \n",
       "19648     293  dude you both are dumb in the heavier than hea...   \n",
       "9845      347                            then i guess i eat poop   \n",
       "10799     728  i thought you were the administrator can you f...   \n",
       "2732      132  not set in new york  why when i deleted the ca...   \n",
       "\n",
       "                                              more_toxic  \n",
       "14331                       i hate drmies he is an idiot  \n",
       "17914  i fuckingg love tacosthere the fuckingg best b...  \n",
       "14390    fuck you fuck you motherfucker go die in a hole  \n",
       "24121                 jimbo wales is a gay little fucker  \n",
       "22424  dude im not angry at you i just think youre a ...  \n",
       "...                                                  ...  \n",
       "13123               youre a mathsci sockpuppet arent you  \n",
       "19648  mahmoud ahmadinejadi added the categoryanti se...  \n",
       "9845   racisttrying to whitewash the terrorists fine ...  \n",
       "10799  just because she has light skin doesnt mean an...  \n",
       "2732   what the hell is that thing on the electoral m...  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "    \n",
    "cleaned_data_shuffle_row = cleaned_data.sample(frac = 1, random_state = 0)\n",
    "\n",
    "\n",
    "cleaned_data_shuffle_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30108"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_row = cleaned_data_shuffle_row.shape[0]\n",
    "total_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>its not so much about the english language its...</td>\n",
       "      <td>i hate drmies he is an idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>431</td>\n",
       "      <td>just read what mr george mcfly said here that ...</td>\n",
       "      <td>i fuckingg love tacosthere the fuckingg best b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>338</td>\n",
       "      <td>a barnstar for you the original barnstar your...</td>\n",
       "      <td>fuck you fuck you motherfucker go die in a hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>i am one who thinks that zappas dad was of ara...</td>\n",
       "      <td>jimbo wales is a gay little fucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>397</td>\n",
       "      <td>a cup of coffee for you get fuckd with coffee</td>\n",
       "      <td>dude im not angry at you i just think youre a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18059</th>\n",
       "      <td>30</td>\n",
       "      <td>i cant imagine anything more depressing than d...</td>\n",
       "      <td>i dont give a fuck.. it will get reposted so y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18060</th>\n",
       "      <td>141</td>\n",
       "      <td>give a reason when you accuse someone of vand...</td>\n",
       "      <td>bullshit=there was no violation you removed fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061</th>\n",
       "      <td>118</td>\n",
       "      <td>additional evidence to above one of the collec...</td>\n",
       "      <td>because you are a fggt do i know you because y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18062</th>\n",
       "      <td>526</td>\n",
       "      <td>omg i am obssessed with twilight and it is my ...</td>\n",
       "      <td>hey gwernol yeah youre a schmuck face thats wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18063</th>\n",
       "      <td>338</td>\n",
       "      <td>jack and jill come on delanoy wheres your sens...</td>\n",
       "      <td>so you assholes are high on power like george ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0           9  its not so much about the english language its...   \n",
       "1         431  just read what mr george mcfly said here that ...   \n",
       "2         338   a barnstar for you the original barnstar your...   \n",
       "3         386  i am one who thinks that zappas dad was of ara...   \n",
       "4         397     a cup of coffee for you get fuckd with coffee    \n",
       "...       ...                                                ...   \n",
       "18059      30  i cant imagine anything more depressing than d...   \n",
       "18060     141   give a reason when you accuse someone of vand...   \n",
       "18061     118  additional evidence to above one of the collec...   \n",
       "18062     526  omg i am obssessed with twilight and it is my ...   \n",
       "18063     338  jack and jill come on delanoy wheres your sens...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0                           i hate drmies he is an idiot  \n",
       "1      i fuckingg love tacosthere the fuckingg best b...  \n",
       "2        fuck you fuck you motherfucker go die in a hole  \n",
       "3                     jimbo wales is a gay little fucker  \n",
       "4      dude im not angry at you i just think youre a ...  \n",
       "...                                                  ...  \n",
       "18059  i dont give a fuck.. it will get reposted so y...  \n",
       "18060  bullshit=there was no violation you removed fa...  \n",
       "18061  because you are a fggt do i know you because y...  \n",
       "18062  hey gwernol yeah youre a schmuck face thats wh...  \n",
       "18063  so you assholes are high on power like george ...  \n",
       "\n",
       "[18064 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = cleaned_data_shuffle_row[:int(total_row*0.6)]\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>an important message block me i can live with...</td>\n",
       "      <td>blockedyour recent behaviour has been utterly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>652</td>\n",
       "      <td>gibnews the truth it is a lie which has been f...</td>\n",
       "      <td>fuck you fred fuck you you bitch ass punk u ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504</td>\n",
       "      <td>the germaine greer quote is highly appropriate...</td>\n",
       "      <td>i hate you i hate you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>567</td>\n",
       "      <td>if this is the sort of community that wants to...</td>\n",
       "      <td>please keep your two cents to yourselfi wasnt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261</td>\n",
       "      <td>this is bull this is y2k all over again this i...</td>\n",
       "      <td>the cherokee comment was a concern because jvm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>655</td>\n",
       "      <td>racisma word describing characteristics of a p...</td>\n",
       "      <td>just for the record castro apologised for his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>472</td>\n",
       "      <td>you are not sorry one damned bit you have yet ...</td>\n",
       "      <td>so called fan sites on wikipedia include info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>131</td>\n",
       "      <td>its all about termination not branches branch...</td>\n",
       "      <td>mgnbar what is a stupid act hi consensus mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>530</td>\n",
       "      <td>thats really shameless weaseling.</td>\n",
       "      <td>moot is a faggot he claims you are a sock pup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>465</td>\n",
       "      <td>ok im stopping now tide roll wouldnt want to m...</td>\n",
       "      <td>deaf culture is full of a bunch of jerks who w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      worker                                         less_toxic  \\\n",
       "0        283   an important message block me i can live with...   \n",
       "1        652  gibnews the truth it is a lie which has been f...   \n",
       "2        504  the germaine greer quote is highly appropriate...   \n",
       "3        567  if this is the sort of community that wants to...   \n",
       "4        261  this is bull this is y2k all over again this i...   \n",
       "...      ...                                                ...   \n",
       "6017     655  racisma word describing characteristics of a p...   \n",
       "6018     472  you are not sorry one damned bit you have yet ...   \n",
       "6019     131   its all about termination not branches branch...   \n",
       "6020     530                  thats really shameless weaseling.   \n",
       "6021     465  ok im stopping now tide roll wouldnt want to m...   \n",
       "\n",
       "                                             more_toxic  \n",
       "0     blockedyour recent behaviour has been utterly ...  \n",
       "1     fuck you fred fuck you you bitch ass punk u ca...  \n",
       "2                                i hate you i hate you.  \n",
       "3     please keep your two cents to yourselfi wasnt ...  \n",
       "4     the cherokee comment was a concern because jvm...  \n",
       "...                                                 ...  \n",
       "6017  just for the record castro apologised for his ...  \n",
       "6018   so called fan sites on wikipedia include info...  \n",
       "6019   mgnbar what is a stupid act hi consensus mean...  \n",
       "6020   moot is a faggot he claims you are a sock pup...  \n",
       "6021  deaf culture is full of a bunch of jerks who w...  \n",
       "\n",
       "[6022 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = cleaned_data_shuffle_row[int(total_row*0.6): int(total_row * 0.8)]\n",
    "val_data = val_data.reset_index(drop = True)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>palestinian christians hi   you have made doz...</td>\n",
       "      <td>re reply at jimbo youre right here about cond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>stop vandalizing wikipedia.</td>\n",
       "      <td>you have been blocked for vandalism to userpag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728</td>\n",
       "      <td>age you might want to reconsider advertising y...</td>\n",
       "      <td>no not really i picked the name to wind up the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>398</td>\n",
       "      <td>the good thing is that you didnt call me mf lol</td>\n",
       "      <td>shitush shitush who are youyou are blatantly a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>the bottom line is that you are a biased contr...</td>\n",
       "      <td>was jesus gayif you say no how do you know wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>422</td>\n",
       "      <td>please stop your disruptive editing if you co...</td>\n",
       "      <td>youre a mathsci sockpuppet arent you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>293</td>\n",
       "      <td>dude you both are dumb in the heavier than hea...</td>\n",
       "      <td>mahmoud ahmadinejadi added the categoryanti se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>347</td>\n",
       "      <td>then i guess i eat poop</td>\n",
       "      <td>racisttrying to whitewash the terrorists fine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>728</td>\n",
       "      <td>i thought you were the administrator can you f...</td>\n",
       "      <td>just because she has light skin doesnt mean an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>132</td>\n",
       "      <td>not set in new york  why when i deleted the ca...</td>\n",
       "      <td>what the hell is that thing on the electoral m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      worker                                         less_toxic  \\\n",
       "0        126   palestinian christians hi   you have made doz...   \n",
       "1        130                        stop vandalizing wikipedia.   \n",
       "2        728  age you might want to reconsider advertising y...   \n",
       "3        398    the good thing is that you didnt call me mf lol   \n",
       "4          2  the bottom line is that you are a biased contr...   \n",
       "...      ...                                                ...   \n",
       "6017     422   please stop your disruptive editing if you co...   \n",
       "6018     293  dude you both are dumb in the heavier than hea...   \n",
       "6019     347                            then i guess i eat poop   \n",
       "6020     728  i thought you were the administrator can you f...   \n",
       "6021     132  not set in new york  why when i deleted the ca...   \n",
       "\n",
       "                                             more_toxic  \n",
       "0      re reply at jimbo youre right here about cond...  \n",
       "1     you have been blocked for vandalism to userpag...  \n",
       "2     no not really i picked the name to wind up the...  \n",
       "3     shitush shitush who are youyou are blatantly a...  \n",
       "4     was jesus gayif you say no how do you know wer...  \n",
       "...                                                 ...  \n",
       "6017               youre a mathsci sockpuppet arent you  \n",
       "6018  mahmoud ahmadinejadi added the categoryanti se...  \n",
       "6019  racisttrying to whitewash the terrorists fine ...  \n",
       "6020  just because she has light skin doesnt mean an...  \n",
       "6021  what the hell is that thing on the electoral m...  \n",
       "\n",
       "[6022 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = cleaned_data_shuffle_row[int(total_row*0.8):]\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>more_toxic_col_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its not so much about the english language its...</td>\n",
       "      <td>i hate drmies he is an idiot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just read what mr george mcfly said here that ...</td>\n",
       "      <td>i fuckingg love tacosthere the fuckingg best b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck you fuck you motherfucker go die in a hole</td>\n",
       "      <td>a barnstar for you the original barnstar your...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jimbo wales is a gay little fucker</td>\n",
       "      <td>i am one who thinks that zappas dad was of ara...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cup of coffee for you get fuckd with coffee</td>\n",
       "      <td>dude im not angry at you i just think youre a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18059</th>\n",
       "      <td>i cant imagine anything more depressing than d...</td>\n",
       "      <td>i dont give a fuck.. it will get reposted so y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18060</th>\n",
       "      <td>give a reason when you accuse someone of vand...</td>\n",
       "      <td>bullshit=there was no violation you removed fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061</th>\n",
       "      <td>additional evidence to above one of the collec...</td>\n",
       "      <td>because you are a fggt do i know you because y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18062</th>\n",
       "      <td>hey gwernol yeah youre a schmuck face thats wh...</td>\n",
       "      <td>omg i am obssessed with twilight and it is my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18063</th>\n",
       "      <td>so you assholes are high on power like george ...</td>\n",
       "      <td>jack and jill come on delanoy wheres your sens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   col_0  \\\n",
       "0      its not so much about the english language its...   \n",
       "1      just read what mr george mcfly said here that ...   \n",
       "2        fuck you fuck you motherfucker go die in a hole   \n",
       "3                     jimbo wales is a gay little fucker   \n",
       "4         a cup of coffee for you get fuckd with coffee    \n",
       "...                                                  ...   \n",
       "18059  i cant imagine anything more depressing than d...   \n",
       "18060   give a reason when you accuse someone of vand...   \n",
       "18061  additional evidence to above one of the collec...   \n",
       "18062  hey gwernol yeah youre a schmuck face thats wh...   \n",
       "18063  so you assholes are high on power like george ...   \n",
       "\n",
       "                                                   col_1  more_toxic_col_idx  \n",
       "0                           i hate drmies he is an idiot                   1  \n",
       "1      i fuckingg love tacosthere the fuckingg best b...                   1  \n",
       "2       a barnstar for you the original barnstar your...                   0  \n",
       "3      i am one who thinks that zappas dad was of ara...                   0  \n",
       "4      dude im not angry at you i just think youre a ...                   1  \n",
       "...                                                  ...                 ...  \n",
       "18059  i dont give a fuck.. it will get reposted so y...                   1  \n",
       "18060  bullshit=there was no violation you removed fa...                   1  \n",
       "18061  because you are a fggt do i know you because y...                   1  \n",
       "18062  omg i am obssessed with twilight and it is my ...                   0  \n",
       "18063  jack and jill come on delanoy wheres your sens...                   0  \n",
       "\n",
       "[18064 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_col_shuffle = pd.DataFrame()\n",
    "indices_moreToxic = []\n",
    "col_1 = []\n",
    "col_0 = []\n",
    "random.seed(0)\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    idx = round(random.uniform(0, 1))\n",
    "    #print('index of more toxic',idx)\n",
    "    \n",
    "    indices_moreToxic.append(idx)#index of where the more toxic comment is \n",
    "        #1 for right column, 0 for left column \n",
    "    \n",
    "    if idx == 1: \n",
    "        col_1.append( train_data['more_toxic'][i])\n",
    "        col_0.append( train_data['less_toxic'][i])\n",
    "        \n",
    "    else:\n",
    "        col_0.append(train_data['more_toxic'][i])\n",
    "        col_1.append( train_data['less_toxic'][i])\n",
    "\n",
    "\n",
    "train_data_col_shuffle['col_0'] = pd.Series(col_0)\n",
    "#trans = pd.DataFrame(comment, columns = ['comment']) // another method of setting to df col\n",
    "\n",
    "train_data_col_shuffle['col_1'] = pd.Series(col_1)\n",
    "train_data_col_shuffle['more_toxic_col_idx'] = pd.DataFrame(indices_moreToxic)\n",
    "\n",
    "train_data_col_shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "T4rexB1zyJYS",
    "outputId": "ea696975-fc17-47a4-9edf-9b8f7522c710",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean the input for predition data\n",
    "cleaned_text = clean_tweets(data_to_test['text'])\n",
    "\n",
    "data_to_test['text'] = pd.DataFrame(cleaned_text)\n",
    "#data_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uVP8iy3t6qtG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract the labels from the train data\n",
    "#y = trans.score.values\n",
    "#X = trans.comment.values\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initalize vectorizer: vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english') #stop_words removed: a, the\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(cleaned_data_shuffle_row.more_toxic.values) + \n",
    "               list(cleaned_data_shuffle_row.less_toxic.values) + list(data_to_test.text.values))\n",
    "    \n",
    "\n",
    "# transform documents to document-term matrix\n",
    "col0_vec = vectorizer.transform(train_data_col_shuffle.col_0)\n",
    "col1_vec = vectorizer.transform(train_data_col_shuffle.col_1)\n",
    "comments_2_score = vectorizer.transform(data_to_test[\"text\"].values)\n",
    "'''\n",
    "# combine col0 and col1\n",
    "col0_1_vec = vectorizer.transform(train_data_col_shuffle.col_0 + ' ' + train_data_col_shuffle.col_1)\n",
    "'''\n",
    "\n",
    "# for testing on the original clean more and less toxic col (unshuffled)\n",
    "more_tox_test_vec = vectorizer.transform(test_data['more_toxic'].values)\n",
    "less_tox_test_vec = vectorizer.transform(test_data['less_toxic'].values)\n",
    "\n",
    "#val set \n",
    "more_tox_val_vec = vectorizer.transform(val_data['more_toxic'].values)\n",
    "less_tox_val_vec = vectorizer.transform(val_data['less_toxic'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6022x46974 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 145363 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_tox_val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6022x46974 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 156890 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_tox_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18064x46974 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 445559 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col0_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6022x46974 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_vec = vectorizer.transform([' ']*6022) #used for testing // a baseline comment to be \n",
    "#biranked against\n",
    "empty_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZKNXtETtcb81"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "# make a function to score the prediction and compare if the \"lesser\" toxic rated is lower prob of rated toxicity\n",
    "def comp_toxicity (model, less_tox_val_vec, more_tox_val_vec):\n",
    "    '''\n",
    "    model is the trained model to be evaluated against the less and more toxic comments\n",
    "    objective is to see if more toxic comments have a higher score\n",
    "\n",
    "    less_tox_val_vec and more_tox_val_vec are the respective column in dataframe that contains the comments vectorized\n",
    "    '''\n",
    "    result = res = np.zeros((1,2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(less_tox_val_vec.shape[0]):\n",
    "        result = rankdata([model.predict_proba(less_tox_val_vec[i]).tolist()[0][1], \n",
    "                 model.predict_proba(more_tox_val_vec[i]).tolist()[0][1]], method = 'ordinal' )\n",
    "        result -= 1\n",
    "        #print(result)\n",
    "        res += result\n",
    "        #print(res[0])\n",
    "        '''\n",
    "        if i == 5:\n",
    "            break\n",
    "        '''\n",
    "    print ('final result: ',res[0])\n",
    "    return res[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18064x93948 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 901644 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "combined_2 = sp.hstack([col0_vec, col1_vec], format='csr') #concatenate the 2 columns for train\n",
    "combined_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6022x93948 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 160583 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_tox_empty_test_vec = sp.hstack([ empty_vec, less_tox_test_vec], format='csr')\n",
    "less_tox_empty_vec = sp.hstack([empty_vec, less_tox_val_vec], format='csr') \n",
    "# need empty_vec on the left side, comp_toxicity assumes more toxic on the right -- toxicity prob score\n",
    "less_tox_empty_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6022x93948 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 144111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_tox_empty_vec = sp.hstack([ empty_vec, more_tox_val_vec], format='csr')\n",
    "more_tox_empty_test_vec = sp.hstack([ empty_vec, more_tox_test_vec], format='csr')\n",
    "more_tox_empty_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CYNXYsi2bin",
    "outputId": "2aefbbac-a60e-4d75-fbc1-3f64456ddafc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final result:  [2143. 3879.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2143., 3879.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)\n",
    "#print(pd.DataFrame(clf.predict(more_tox_empty_vec)).value_counts()) #does predict more toxic against baseline\n",
    "#print(pd.DataFrame(clf.predict(less_tox_empty_vec)).value_counts()) # does predict ' ' as more toxic than non-toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxFOh2JRkELg",
    "outputId": "758aff87-be81-4a6d-c52e-7da477e1eedc"
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8KtIcgUrLd5",
    "outputId": "5979915e-721e-4552-8ce4-f77f71a265a0"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "#choose neighbours after the cv \n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(combined_2, cleaned_data_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec, more_tox_empty_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkabtg_J2bsx",
    "outputId": "9396100c-97d4-4ad6-af03-f3170b49c04e"
   },
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "clf = svm.SVC(kernel='linear', C=C, probability = True)\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=C, probability = True)\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)\n",
    "\n",
    "clf = svm.SVC(kernel='sigmoid', C=C, probability = True)\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)\n",
    "\n",
    "clf = svm.SVC(kernel='poly', C=C, probability = True)\n",
    "clf.fit(combined_2, train_data_col_shuffle.more_toxic_col_idx )\n",
    "comp_toxicity(clf, less_tox_empty_vec , more_tox_empty_vec)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYo75kf50wzd"
   },
   "source": [
    "# cross validation on different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hClBlkVlyJYS",
    "outputId": "587386d2-76d1-4ef1-b614-afad2a11b040",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ericling/Documents/GitHub/DataSci Projects/KaggleToxicity/Kaggle_ToxicityRater/kaggle_kernel/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6305367461716801"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "cv_scores = cross_val_score(clf, combined_2, train_data_col_shuffle.more_toxic_col_idx, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5zBWM7YyJYS",
    "outputId": "f07ca3b1-7db5-4b24-f0af-ad460afa2611"
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "cv_scores = cross_val_score(clf, combined_2, train_data_col_shuffle.more_toxic_col_idx,\n",
    "                            cv=10)\n",
    "\n",
    "print ('random forest: ',cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRb4DqUuyJYS",
    "outputId": "ad80a73c-2ae1-42db-bb62-1a0ddaf951a2"
   },
   "outputs": [],
   "source": [
    "#KNN choosing best neighbour number \n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "for n in range(1, 15):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    cv_scores = cross_val_score(clf,combined_2, train_data_col_shuffle.more_toxic_col_idx\n",
    "                                , cv=10)\n",
    "    print (n, cv_scores.mean())\n",
    "    \n",
    "#k = 8 , 3 are first and sec place for best predictor respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8g2TuWMyJYS",
    "outputId": "d01dc6a3-90ba-42e6-eeb3-41563dba4bff"
   },
   "outputs": [],
   "source": [
    "#KNN \n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=8)\n",
    "cv_scores = cross_val_score(clf, combined_2, train_data_col_shuffle.more_toxic_col_idx,\n",
    "                            cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx0H3_S_yJYS",
    "outputId": "47099c8d-ca34-4992-af09-4ecb18cf14b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax scaled Baye's:  0.6335798215503754\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "#usually not the best performance, but fast to train\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "scaler = preprocessing.MaxAbsScaler() #don't really need scaling since the input is already binary \n",
    "training_inputs_minmax = scaler.fit_transform(combined_2)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores = cross_val_score(clf, combined_2, train_data_col_shuffle.more_toxic_col_idx, cv=10)\n",
    "\n",
    "print ('minmax scaled Baye\\'s: ',cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0_RUV73yJYS",
    "outputId": "03ccc045-f3cf-4554-8563-098010f8ff48"
   },
   "outputs": [],
   "source": [
    "#SVM with kernel tuning\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "C = 1.0\n",
    "svc = svm.SVC(kernel='linear', C=C)\n",
    "cv_scores = cross_val_score(svc,combined_2, train_data_col_shuffle.more_toxic_col_idx\n",
    "                            , cv=10)\n",
    "print ('linear kernel', cv_scores.mean())\n",
    "\n",
    "\n",
    "svc = svm.SVC(kernel='rbf', C=C)\n",
    "cv_scores = cross_val_score(svc, combined_2, train_data_col_shuffle.more_toxic_col_idx,\n",
    "                            cv=10)\n",
    "cv_scores.mean()\n",
    "print ('rbf kernel', cv_scores.mean())\n",
    "\n",
    "\n",
    "svc = svm.SVC(kernel='sigmoid', C=C)\n",
    "cv_scores = cross_val_score(svc, combined_2, train_data_col_shuffle.more_toxic_col_idx\n",
    "                            , cv=10)\n",
    "cv_scores.mean()\n",
    "print ('sigmoid kernel', cv_scores.mean())\n",
    "\n",
    "svc = svm.SVC(kernel='poly', C=C)\n",
    "cv_scores = cross_val_score(svc, combined_2, train_data_col_shuffle.more_toxic_col_idx\n",
    "                            , cv=10)\n",
    "cv_scores.mean()\n",
    "print ('poly kernel', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jtg47bIyJYS"
   },
   "source": [
    "# try on colab: keras lstm, xgb \n",
    "\n",
    "Didn't try LSTM on biranked training, because the other models' accuracy didn't seem to improve with this biranked training of data transformation vs. the training done on rating aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOGyFLqQ0d8s",
    "outputId": "3716f3c2-b0b8-4ef5-f983-c88fc7b3dfec"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-oSlXPbyJYS",
    "outputId": "9fe17c8f-5648-44a1-9da6-dc28eed54b6e"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier( eta = 0.6 ,objective = 'multi:softmax', num_class = 2) #eta higher starts losing acc -- lower is slower\n",
    "cv_scores = cross_val_score(clf, combined_2, train_data_col_shuffle.more_toxic_col_idx\n",
    "                            , cv=10)\n",
    "print (cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5GB-FkZX_Dl"
   },
   "source": [
    "# Improvement\n",
    "Transfer learning on BERT sentiment analysis -- change out the last layer to fine tune the range of ranking capabilities. Can try to tune those pre-trained transformer models to biranked or aggregated data provided in this competition. See if this method offers higher prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-qWPX4DX_Gb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcYuPMyRLckB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch7QklDnLcmY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kaggle_kernel",
   "language": "python",
   "name": "kaggle_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
